
# EPFO Member Transfer Analysis Project

## 1. Project Overview
This project provides a suite of tools for analyzing simulated member transfer data between establishments, mimicking patterns observed in Employee Provident Fund Organization (EPFO) data. It allows users to generate sample data, perform various static graph analyses, and explore temporal link prediction using Graph Neural Networks (GNNs).

## 2. Features
The project offers several types of analyses:
*   **Establishment-Level Insights**: Metrics about individual establishments (nodes), such as top sources/destinations of members, net gainers/losers, and centrality measures.
*   **Transfer Pattern Insights**: Analysis of the transfers (edges) themselves, including dominant routes, reciprocal transfers, and patterns based on establishment attributes like industry, location, and size.
*   **Network Structure & Community Insights**: Global network properties like density, community detection using the Louvain algorithm, and identification of bridge establishments connecting different communities.
*   **Temporal Link Prediction**: Utilizes PyTorch Geometric to train a GNN model for predicting future member transfers based on simulated temporal data patterns.

## 3. Project Structure
The project is organized into the following key Python files:

*   `data.py`: Handles data-related tasks.
    *   Generates sample establishment and transfer data.
    *   Loads data from CSV files.
    *   Saves data to CSV (`epfo_establishments_nodes.csv`, `epfo_transfers_edges.csv`).
    *   Exports the graph to GEXF format (`epfo_transfers_graph.gexf`) for visualization in tools like Gephi.
*   `graph_analysis.py`: Contains the core analytical functions that operate on graph data. This includes functions for all establishment, transfer, and network structure insights.
*   `run_analysis.py`: The main command-line interface for running the static graph analyses available in `graph_analysis.py`. It allows users to select data sources, choose specific analyses to perform, and customize parameters.
*   `main.py`: Implements the temporal link prediction component using PyTorch and PyTorch Geometric. It generates its own simulated temporal graph data for this purpose.
*   `requirements.txt`: Lists all Python dependencies required for the project.

## 4. Setup and Installation

1.  **Clone the Repository (if applicable)**:
    If you have downloaded this project as a ZIP, extract it. If it's a Git repository, clone it:
    ```bash
    # git clone <repository_url> # Replace with actual URL if hosted
    # cd <repository_directory>
    ```

2.  **Install Dependencies**:
    It's recommended to use a virtual environment (e.g., `venv` or `conda`) to manage dependencies.
    Install the required packages using:
    ```bash
    pip install -r requirements.txt
    ```

3.  **Notes on PyTorch and PyTorch Geometric**:
    The `requirements.txt` file lists `torch` and `torch-geometric`. The installation of PyTorch Geometric and its dependencies (like `torch-scatter`, `torch-sparse`, etc.) can sometimes be platform-specific or require versions compatible with your PyTorch and CUDA setup.
    If you encounter issues with the `pip install -r requirements.txt` for these packages, it's often best to install them separately by following the official PyTorch Geometric installation instructions. This typically involves a command similar to:
    ```bash
    # Example for a specific PyTorch version and CUDA (adjust as needed):
    # pip install torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric -f https://data.pyg.org/whl/torch-$(python -c "import torch; print(torch.__version__)").html
    ```
    Ensure you have a compatible version of PyTorch installed first. Refer to the [PyTorch Geometric documentation](https://pytorch-geometric.readthedocs.io/en/latest/install/installation.html) for detailed guidance.

## 5. Data
The project can work with two types of data:

*   **Sample Data**: Generated internally by `data.py` (if run directly) or by `run_analysis.py` when using the `sample` data source. This is useful for quick demonstrations and testing.
    *   Default node file: `epfo_establishments_nodes.csv`
    *   Default edge file: `epfo_transfers_edges.csv`
*   **CSV Data**: You can provide your own data in CSV format. The files should follow the structure of the sample data generated by the script.
    *   **Nodes CSV (`epfo_establishments_nodes.csv`)**: Must contain at least `establishment_id` and other optional attributes like `name`, `industry`, `city`, `size_category`.
    *   **Edges CSV (`epfo_transfers_edges.csv`)**: Must contain `source_establishment_id`, `target_establishment_id`, and `members_transferred`.
*   **GEXF Export**: When data is generated or loaded, `data.py` (if its saving functions are triggered, e.g., by its `if __name__ == "__main__":` block) can save the graph as `epfo_transfers_graph.gexf`. This file can be imported into graph visualization software like [Gephi](https://gephi.org/) to explore the network visually.

## 6. Running Analyses (Static Graph Insights via `run_analysis.py`)
The `run_analysis.py` script is the primary way to perform static graph analyses.

*   **Basic Command (uses sample data and runs no specific analysis by default, just loads graph):**
    ```bash
    python run_analysis.py
    ```

*   **Key Command-Line Arguments**:
    *   `--data_source <source>`: Specify data origin.
        *   `sample` (default): Use built-in sample data.
        *   `csv`: Use data from CSV files. When using `csv`, you can also specify `--nodes_csv <path>` and `--edges_csv <path>` if your files are not named `epfo_establishments_nodes.csv` and `epfo_transfers_edges.csv` or are in a different directory.
    *   `--run_establishment_insights`: Perform establishment-level analyses.
    *   `--run_transfer_insights`: Perform transfer pattern analyses.
    *   `--run_network_insights`: Perform network structure and community detection analyses.
    *   `--run_all_insights`: A shortcut to run all the above insight categories.
    *   `--top_n <number>`: Define the number of items for top-N lists (e.g., top 5 sources). Default is 5.
    *   `--industry_A <name> [--industry_B <name>]`: For industry-specific transfer analysis. If only `industry_A` is given, analyzes intra-industry patterns. If `industry_B` is also given, analyzes inter-industry patterns from A to B.
    *   `--location_A <name> [--location_B <name>]`: For location-specific transfer analysis (uses 'city' attribute).
    *   `--size_A <name> [--size_B <name>]`: For size-category-specific transfer analysis.

*   **Examples**:
    1.  Run all analyses on sample data and show top 10 results where applicable:
        ```bash
        python run_analysis.py --run_all_insights --top_n 10
        ```
    2.  Run transfer pattern analysis for "Information Technology" establishments using sample data:
        ```bash
        python run_analysis.py --run_transfer_insights --industry_A "Information Technology"
        ```
    3.  Run transfer pattern analysis between "Manufacturing" and "Logistics" industries:
        ```bash
        python run_analysis.py --run_transfer_insights --industry_A "Manufacturing" --industry_B "Logistics"
        ```
    4.  Run establishment insights using data from custom CSV files:
        ```bash
        python run_analysis.py --data_source csv --nodes_csv path/to/my_nodes.csv --edges_csv path/to/my_edges.csv --run_establishment_insights
        ```

## 7. Running Temporal Link Prediction (via `main.py`)
The `main.py` script handles temporal link prediction using a GNN model (typically a GCN-LSTM or similar architecture) built with PyTorch Geometric.

*   **Purpose**: To predict future member transfers (links) in the graph based on patterns observed in a sequence of graph snapshots over time.
*   **Data**: This script generates its own simulated temporal data. It does not use the static CSV files or sample data from `data.py` directly for the temporal modeling part.
*   **Command**:
    ```bash
    python main.py
    ```
*   **Output**: The script will typically output training progress (loss, accuracy/AUC) and evaluation results for the link prediction task.

## 8. Outputs
*   **`run_analysis.py`**: Prints all results (DataFrames, lists, metrics) directly to the console, formatted for readability.
*   **`data.py`**: If run directly (`python data.py`) or if its saving functions are explicitly called, it will generate:
    *   `epfo_establishments_nodes.csv`: CSV file of establishment data.
    *   `epfo_transfers_edges.csv`: CSV file of transfer data.
    *   `epfo_transfers_graph.gexf`: A GEXF file for graph visualization.
*   **`main.py`**: Prints training and evaluation metrics for the temporal link prediction model to the console.

## 9. (Optional) Extending the Analysis
The project is designed to be extensible. New graph analysis functions can be added to `graph_analysis.py`. These functions can then be integrated into `run_analysis.py` by:
1.  Importing the new function in `run_analysis.py`.
2.  Adding relevant command-line arguments if customization is needed.
3.  Calling the function within the appropriate analysis block (e.g., establishment, transfer, network) in `run_analysis.py`.

This allows for easy expansion of the analytical capabilities.